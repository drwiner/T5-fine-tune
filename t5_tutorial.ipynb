{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:23:25.157807Z",
     "start_time": "2023-05-19T14:23:25.151091Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import logging\n",
    "import random\n",
    "\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (AdamW, T5ForConditionalGeneration, T5Tokenizer, get_linear_schedule_with_warmup)\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from termcolor import colored\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:25:46.516414Z",
     "start_time": "2023-05-19T12:25:46.502138Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "with Path(\"./datasets/QA/BioASQ/BioASQ-train-factoid-4b.json\").open() as json_file:\n",
    "    data = json.load(json_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:53:41.599148Z",
     "start_time": "2023-05-19T12:53:41.573140Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['data', 'version'])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:54:06.495071Z",
     "start_time": "2023-05-19T12:54:06.493102Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data[\"version\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['paragraphs', 'title'])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"data\"][0].keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:54:32.819548Z",
     "start_time": "2023-05-19T12:54:32.817593Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "'BioASQ6b'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"data\"][0][\"title\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:54:43.685173Z",
     "start_time": "2023-05-19T12:54:43.683748Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "3266"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"data\"][0][\"paragraphs\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:55:15.837966Z",
     "start_time": "2023-05-19T12:55:15.834179Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "questions = data[\"data\"][0][\"paragraphs\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:55:29.133723Z",
     "start_time": "2023-05-19T12:55:29.116624Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "{'qas': [{'id': '52bf208003868f1b06000019_002',\n   'question': 'What is the inheritance pattern of Li–Fraumeni syndrome?',\n   'answers': [{'text': 'autosomal dominant', 'answer_start': 213}]}],\n 'context': 'Balanced t(11;15)(q23;q15) in a TP53+/+ breast cancer patient from a Li-Fraumeni syndrome family. Li-Fraumeni Syndrome (LFS) is characterized by early-onset carcinogenesis involving multiple tumor types and shows autosomal dominant inheritance. Approximately 70% of LFS cases are due to germline mutations in the TP53 gene on chromosome 17p13.1. Mutations have also been found in the CHEK2 gene on chromosome 22q11, and others have been mapped to chromosome 11q23. While characterizing an LFS family with a documented defect in TP53, we found one family member who developed bilateral breast cancer at age 37 yet was homozygous for wild-type TP53. Her mother also developed early-onset primary bilateral breast cancer, and a sister had unilateral breast cancer and a soft tissue sarcoma. Cytogenetic analysis using fluorescence in situ hybridization of a primary skin fibroblast cell line revealed that the patient had a novel balanced reciprocal translocation between the long arms of chromosomes 11 and 15: t(11;15)(q23;q15). This translocation was not present in a primary skin fibroblast cell line from a brother with neuroblastoma, who was heterozygous for the TP53 mutation. There was no evidence of acute lymphoblastic leukemia in either the patient or her mother, although a nephew did develop leukemia and died in childhood. These data may implicate the region at breakpoint 11q23 and/or 15q15 as playing a significant role in predisposition to breast cancer development.'}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T12:55:36.623856Z",
     "start_time": "2023-05-19T12:55:36.619935Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def extract_questions_and_answer(factoid_path: Path):\n",
    "    with factoid_path.open() as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    questions = data[\"data\"][0][\"paragraphs\"]\n",
    "    data_rows = []\n",
    "\n",
    "    for question in questions:\n",
    "        context = question[\"context\"]\n",
    "        for qa in question[\"qas\"]:\n",
    "            question_text = qa[\"question\"]\n",
    "            answer_text = qa[\"answers\"]\n",
    "            for answer in answer_text:\n",
    "                answer_text = answer[\"text\"]\n",
    "                answer_start = answer[\"answer_start\"]\n",
    "                answer_end = answer_start + len(answer_text)\n",
    "\n",
    "                data_rows.append({\n",
    "                    \"question\": question_text,\n",
    "                    \"context\": context,\n",
    "                    \"answer\": answer_text,\n",
    "                    \"answer_start\": answer_start,\n",
    "                    \"answer_end\": answer_end\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(data_rows)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:04:30.021631Z",
     "start_time": "2023-05-19T13:04:30.018550Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            question   \n0  What is the inheritance pattern of Li–Fraumeni...  \\\n1  What is the inheritance pattern of Li–Fraumeni...   \n2    Which type of lung cancer is afatinib used for?   \n3  Which hormone abnormalities are characteristic...   \n4  Which hormone abnormalities are characteristic...   \n\n                                             context              answer   \n0  Balanced t(11;15)(q23;q15) in a TP53+/+ breast...  autosomal dominant  \\\n1  Genetic modeling of Li-Fraumeni syndrome in ze...  autosomal dominant   \n2  Clinical perspective of afatinib in non-small ...   EGFR-mutant NSCLC   \n3  DOCA sensitive pendrin expression in kidney, h...             thyroid   \n4  Clinical and molecular characteristics of Pend...             thyroid   \n\n   answer_start  answer_end  \n0           213         231  \n1           105         123  \n2          1203        1220  \n3           419         426  \n4           705         712  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>context</th>\n      <th>answer</th>\n      <th>answer_start</th>\n      <th>answer_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n      <td>Balanced t(11;15)(q23;q15) in a TP53+/+ breast...</td>\n      <td>autosomal dominant</td>\n      <td>213</td>\n      <td>231</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n      <td>Genetic modeling of Li-Fraumeni syndrome in ze...</td>\n      <td>autosomal dominant</td>\n      <td>105</td>\n      <td>123</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Which type of lung cancer is afatinib used for?</td>\n      <td>Clinical perspective of afatinib in non-small ...</td>\n      <td>EGFR-mutant NSCLC</td>\n      <td>1203</td>\n      <td>1220</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Which hormone abnormalities are characteristic...</td>\n      <td>DOCA sensitive pendrin expression in kidney, h...</td>\n      <td>thyroid</td>\n      <td>419</td>\n      <td>426</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Which hormone abnormalities are characteristic...</td>\n      <td>Clinical and molecular characteristics of Pend...</td>\n      <td>thyroid</td>\n      <td>705</td>\n      <td>712</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_questions_and_answer(Path(\"./datasets/QA/BioASQ/BioASQ-train-factoid-4b.json\")).head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:09:30.672300Z",
     "start_time": "2023-05-19T13:09:30.648121Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "[PosixPath('datasets/QA/BioASQ/BioASQ-train-factoid-4b.json'),\n PosixPath('datasets/QA/BioASQ/BioASQ-train-factoid-5b.json'),\n PosixPath('datasets/QA/BioASQ/BioASQ-train-factoid-6b.json'),\n PosixPath('datasets/QA/BioASQ/BioASQ-train-factoid-7b.json')]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factoid_paths = sorted(list(Path(\"./datasets/QA/BioASQ\").glob(\"BioASQ-train-factoid-*\")))\n",
    "factoid_paths"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:12:15.262280Z",
     "start_time": "2023-05-19T13:12:15.258056Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for factoid_path in factoid_paths:\n",
    "    dfs.append(extract_questions_and_answer(factoid_path))\n",
    "\n",
    "df = pd.concat(dfs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:12:53.544096Z",
     "start_time": "2023-05-19T13:12:53.453624Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            question   \n0  What is the inheritance pattern of Li–Fraumeni...  \\\n1  What is the inheritance pattern of Li–Fraumeni...   \n2    Which type of lung cancer is afatinib used for?   \n3  Which hormone abnormalities are characteristic...   \n4  Which hormone abnormalities are characteristic...   \n\n                                             context              answer   \n0  Balanced t(11;15)(q23;q15) in a TP53+/+ breast...  autosomal dominant  \\\n1  Genetic modeling of Li-Fraumeni syndrome in ze...  autosomal dominant   \n2  Clinical perspective of afatinib in non-small ...   EGFR-mutant NSCLC   \n3  DOCA sensitive pendrin expression in kidney, h...             thyroid   \n4  Clinical and molecular characteristics of Pend...             thyroid   \n\n   answer_start  answer_end  \n0           213         231  \n1           105         123  \n2          1203        1220  \n3           419         426  \n4           705         712  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>context</th>\n      <th>answer</th>\n      <th>answer_start</th>\n      <th>answer_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n      <td>Balanced t(11;15)(q23;q15) in a TP53+/+ breast...</td>\n      <td>autosomal dominant</td>\n      <td>213</td>\n      <td>231</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n      <td>Genetic modeling of Li-Fraumeni syndrome in ze...</td>\n      <td>autosomal dominant</td>\n      <td>105</td>\n      <td>123</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Which type of lung cancer is afatinib used for?</td>\n      <td>Clinical perspective of afatinib in non-small ...</td>\n      <td>EGFR-mutant NSCLC</td>\n      <td>1203</td>\n      <td>1220</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Which hormone abnormalities are characteristic...</td>\n      <td>DOCA sensitive pendrin expression in kidney, h...</td>\n      <td>thyroid</td>\n      <td>419</td>\n      <td>426</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Which hormone abnormalities are characteristic...</td>\n      <td>Clinical and molecular characteristics of Pend...</td>\n      <td>thyroid</td>\n      <td>705</td>\n      <td>712</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:12:58.298410Z",
     "start_time": "2023-05-19T13:12:58.292737Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "(17219, 5)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:13:02.986375Z",
     "start_time": "2023-05-19T13:13:02.983314Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "557"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.question.unique())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:15:52.836398Z",
     "start_time": "2023-05-19T13:15:52.832566Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "6161"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.context.unique())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:16:05.610500Z",
     "start_time": "2023-05-19T13:16:05.561313Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "sample_question = df.iloc[240]\n",
    "sample_question"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:17:12.530224Z",
     "start_time": "2023-05-19T13:17:12.527992Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def color_answer(question):\n",
    "    answer_start, answer_end = question[\"answer_start\"], question[\"answer_end\"]\n",
    "    context = question[\"context\"]\n",
    "\n",
    "    return colored(context[:answer_start], \"white\") + colored(context[answer_start:answer_end], \"green\") + colored(context[answer_end:], \"white\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:35:44.636027Z",
     "start_time": "2023-05-19T13:35:44.633938Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[97mAdductor laryngeal breathing dystonia in a patient with lubag (\u001B[0m\u001B[32mX-linked dystonia-Parkinsonism\u001B[0m\u001B[97m syndrome). We report a patient with Lubag (X-linked dystonia-parkinsonism) who presented with severe respiratory stridor from adductor laryngeal breathing dystonia. Emergency tracheostomy was necessary, and subsequent laryngeal injection with botulinum toxin led to worsening aspiration. Botulinum toxin injection for severe lingual dystonia was successful.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "print(color_answer(sample_question))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:35:26.708925Z",
     "start_time": "2023-05-19T13:35:26.704510Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83b76006339e459e8e11665e98b92c2b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "320dabcee7ce43bb959680f177e11074"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/drw/venv_miniforge310/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"t5-base\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:36:54.135936Z",
     "start_time": "2023-05-19T13:36:53.722779Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [5328, 27, 1066, 36, 3, 27625, 42, 1858, 58, 1, 6844, 5, 2867, 5, 27, 241, 151, 12, 36, 7403, 13, 149, 231, 79, 333, 140, 5, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoding = tokenizer(\n",
    "    \"Would I rather be feared or loved?\",\n",
    "    \"Easy. Both. I want people to be afraid of how much they love me.\"\n",
    ")\n",
    "sample_encoding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:38:06.616587Z",
     "start_time": "2023-05-19T13:38:06.613461Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "preds = [\n",
    "    tokenizer.decode(input_id, skip_special_tokens=False, clean_up_tokenization_spaces=True)\n",
    "    for input_id in sample_encoding[\"input_ids\"]\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:40:11.444249Z",
     "start_time": "2023-05-19T13:40:11.441433Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "'Would I rather be  feared or loved ? </s> Easy . Both . I want people to be afraid of how much they love me . </s>'"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(preds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:40:13.495153Z",
     "start_time": "2023-05-19T13:40:13.490966Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "encoding = tokenizer(\n",
    "    sample_question[\"question\"],\n",
    "    sample_question[\"context\"],\n",
    "    max_length=512,\n",
    "    padding=\"max_length\",\n",
    "    truncation=\"only_second\",\n",
    "    return_attention_mask=True,\n",
    "    add_special_tokens=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:45:09.158322Z",
     "start_time": "2023-05-19T13:45:09.155553Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['input_ids', 'attention_mask'])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:45:14.022272Z",
     "start_time": "2023-05-19T13:45:14.019267Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "'What is the synonym of the lubag disease?</s> Adductor laryngeal breathing dystonia in a patient with lubag (X-linked dystonia-Parkinsonism syndrome). We report a patient with Lubag (X-linked dystonia-parkinsonism) who presented with severe respiratory stridor from adductor laryngeal breathing dystonia. Emergency tracheostomy was necessary, and subsequent laryngeal injection with botulinum toxin led to worsening aspiration. Botulinum toxin injection for severe lingual dystonia was successful.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoding[\"input_ids\"].squeeze())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:45:39.865554Z",
     "start_time": "2023-05-19T13:45:39.851081Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "question                What is the synonym of the lubag disease?\ncontext         Adductor laryngeal breathing dystonia in a pat...\nanswer                             X-linked dystonia-Parkinsonism\nanswer_start                                                   63\nanswer_end                                                     93\nName: 240, dtype: object"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:46:24.662038Z",
     "start_time": "2023-05-19T13:46:24.658020Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "answer_encoding = tokenizer(\n",
    "    sample_question[\"answer\"],\n",
    "    max_length=32,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_attention_mask=True,\n",
    "    add_special_tokens=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:46:31.687433Z",
     "start_time": "2023-05-19T13:46:31.684922Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "'X-linked dystonia-Parkinsonism</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(answer_encoding[\"input_ids\"].squeeze())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:46:40.896280Z",
     "start_time": "2023-05-19T13:46:40.893367Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "labels = answer_encoding[\"input_ids\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:47:20.064505Z",
     "start_time": "2023-05-19T13:47:20.061338Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[    3,     4,    18, 29000, 16633,    17,  8008,    18, 13212,  7815,\n            32, 14378,     1,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100]])"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:47:47.955399Z",
     "start_time": "2023-05-19T13:47:47.935837Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "labels[labels == 0] = -100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:47:38.806001Z",
     "start_time": "2023-05-19T13:47:38.797635Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "class BioQADataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data: pd.DataFrame,\n",
    "            tokenizer: T5Tokenizer,\n",
    "            source_max_token_len: int = 396,\n",
    "            target_max_token_len: int = 32,\n",
    "            ):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "\n",
    "        self.source_max_token_len = source_max_token_len\n",
    "        self.target_max_token_len = target_max_token_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "        source_encoding = tokenizer(\n",
    "            data_row[\"question\"],\n",
    "            data_row[\"context\"],\n",
    "            max_length=self.source_max_token_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=\"only_second\",\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        target_encoding = tokenizer(\n",
    "            data_row[\"answer\"],\n",
    "            max_length=self.target_max_token_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        labels = target_encoding[\"input_ids\"]\n",
    "        labels[labels == 0] = -100\n",
    "\n",
    "        return dict(\n",
    "            question=data_row[\"question\"],\n",
    "            context=data_row[\"context\"],\n",
    "            answer=data_row[\"answer\"],\n",
    "            input_ids=source_encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=source_encoding[\"attention_mask\"].flatten(),\n",
    "            labels=labels.flatten()\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:37:24.050434Z",
     "start_time": "2023-05-19T14:37:24.047837Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "sample_dataset = BioQADataset(df, tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:37:24.054109Z",
     "start_time": "2023-05-19T14:37:24.051929Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the inheritance pattern of Li–Fraumeni syndrome?\n",
      "autosomal dominant\n",
      "tensor([  363,    19,     8, 28915,  3275,    13,  1414,   104,   371,  6340])\n",
      "tensor([ 1510, 10348,   138, 12613,     1,  -100,  -100,  -100,  -100,  -100])\n"
     ]
    }
   ],
   "source": [
    "for data in sample_dataset:\n",
    "    print(data[\"question\"])\n",
    "    print(data[\"answer\"])\n",
    "    print(data[\"input_ids\"][:10])\n",
    "    print(data[\"labels\"][:10])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:56:50.227599Z",
     "start_time": "2023-05-19T13:56:50.223387Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.05)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:57:18.115121Z",
     "start_time": "2023-05-19T13:57:18.107218Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "((16358, 5), (861, 5))"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T13:57:25.367665Z",
     "start_time": "2023-05-19T13:57:25.363504Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "class BioQADataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            train_df: pd.DataFrame,\n",
    "            val_df: pd.DataFrame,\n",
    "            tokenizer: T5Tokenizer,\n",
    "            batch_size: int = 8,\n",
    "            source_max_token_len: int = 396,\n",
    "            target_max_token_len: int = 32,\n",
    "            ):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.source_max_token_len = source_max_token_len\n",
    "        self.target_max_token_len = target_max_token_len\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = BioQADataset(\n",
    "            data=self.train_df,\n",
    "            tokenizer=self.tokenizer,\n",
    "            source_max_token_len=self.source_max_token_len,\n",
    "            target_max_token_len=self.target_max_token_len\n",
    "        )\n",
    "\n",
    "        self.val_dataset = BioQADataset(\n",
    "            self.val_df,\n",
    "            self.tokenizer,\n",
    "            self.source_max_token_len,\n",
    "            self.target_max_token_len\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=4\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:34:32.763010Z",
     "start_time": "2023-05-19T14:34:32.757131Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "smaller_df = df.drop_duplicates(subset=[\"context\"], inplace=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:06:07.360989Z",
     "start_time": "2023-05-19T14:06:07.357259Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "(6161, 5)"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:06:14.396612Z",
     "start_time": "2023-05-19T14:06:14.391687Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(smaller_df, test_size=0.05)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:06:43.159925Z",
     "start_time": "2023-05-19T14:06:43.155142Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "N_EPOCHS = 1\n",
    "\n",
    "data_module = BioQADataModule(train_df=train_df, val_df=val_df, tokenizer=tokenizer, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:34:40.487414Z",
     "start_time": "2023-05-19T14:34:40.480059Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "data_module.setup()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:34:44.644706Z",
     "start_time": "2023-05-19T14:34:44.636694Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0d223ce626540948581d070879f713c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9de3c0e10cf54c9285cce7615c3378ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(model_name, return_dict=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:09:21.464834Z",
     "start_time": "2023-05-19T14:08:55.290824Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "input_ids = tokenizer(\n",
    "    \"translate English to German: What is the name of my dog?\",\n",
    "    return_tensors=\"pt\"\n",
    ").input_ids"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:13:45.392693Z",
     "start_time": "2023-05-19T14:13:45.390081Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "generated_ids = model.generate(input_ids=input_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:13:46.945089Z",
     "start_time": "2023-05-19T14:13:46.746218Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "preds = [\n",
    "    tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    for g in generated_ids\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:13:48.124857Z",
     "start_time": "2023-05-19T14:13:48.122338Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "'Was ist der Name meines Hundes?'"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(preds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:13:49.547602Z",
     "start_time": "2023-05-19T14:13:49.543177Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\n",
    "\n",
    "This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\n",
    "\n",
    "[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\n",
    "\n",
    "Useful Resources\n",
    "\n",
    "OpenAI Cookbook has many in-depth examples for how to utilize LLM efficiently.\n",
    "LangChain, a library for combining language models with other components to build applications.\n",
    "Prompt Engineering Guide repo contains a pretty comprehensive collection of education materials on prompt engineering.\n",
    "learnprompting.org\n",
    "PromptPerfect\n",
    "Semantic Kernel\n",
    "Basic Prompting\n",
    "Zero-shot and few-shot learning are two most basic approaches for prompting the model, pioneered by many LLM papers and commonly used for benchmarking LLM performance.\n",
    "\n",
    "Zero-Shot\n",
    "Zero-shot learning is to simply feed the task text to the model and ask for results.\n",
    "\n",
    "(All the sentiment analysis examples are from SST-2)\n",
    "\n",
    "Text: i'll bet the video game is a lot more fun than the film.\n",
    "Sentiment:\n",
    "Few-shot\n",
    "Few-shot learning presents a set of high-quality demonstrations, each consisting of both input and desired output, on the target task. As the model first sees good examples, it can better understand human intention and criteria for what kinds of answers are wanted. Therefore, few-shot learning often leads to better performance than zero-shot. However, it comes at the cost of more token consumption and may hit the context length limit when input and output text are long.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:14:50.455596Z",
     "start_time": "2023-05-19T14:14:50.453272Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "input_ids = tokenizer(\n",
    "    \"summarize: \" + text,\n",
    "    return_tensors=\"pt\"\n",
    ").input_ids"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:15:24.136902Z",
     "start_time": "2023-05-19T14:15:24.134485Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "generated_ids = model.generate(input_ids=input_ids)\n",
    "\n",
    "preds = [\n",
    "    tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    for g in generated_ids\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:15:33.575781Z",
     "start_time": "2023-05-19T14:15:33.070023Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "'prompt engineering is a method for communicating with an autoregressive language model. it'"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(preds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:15:37.703310Z",
     "start_time": "2023-05-19T14:15:37.699545Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "T5Config {\n  \"_name_or_path\": \"t5-base\",\n  \"architectures\": [\n    \"T5ForConditionalGeneration\"\n  ],\n  \"d_ff\": 3072,\n  \"d_kv\": 64,\n  \"d_model\": 768,\n  \"decoder_start_token_id\": 0,\n  \"dense_act_fn\": \"relu\",\n  \"dropout_rate\": 0.1,\n  \"eos_token_id\": 1,\n  \"feed_forward_proj\": \"relu\",\n  \"initializer_factor\": 1.0,\n  \"is_encoder_decoder\": true,\n  \"is_gated_act\": false,\n  \"layer_norm_epsilon\": 1e-06,\n  \"model_type\": \"t5\",\n  \"n_positions\": 512,\n  \"num_decoder_layers\": 12,\n  \"num_heads\": 12,\n  \"num_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"relative_attention_max_distance\": 128,\n  \"relative_attention_num_buckets\": 32,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"early_stopping\": true,\n      \"length_penalty\": 2.0,\n      \"max_length\": 200,\n      \"min_length\": 30,\n      \"no_repeat_ngram_size\": 3,\n      \"num_beams\": 4,\n      \"prefix\": \"summarize: \"\n    },\n    \"translation_en_to_de\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to German: \"\n    },\n    \"translation_en_to_fr\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to French: \"\n    },\n    \"translation_en_to_ro\": {\n      \"early_stopping\": true,\n      \"max_length\": 300,\n      \"num_beams\": 4,\n      \"prefix\": \"translate English to Romanian: \"\n    }\n  },\n  \"transformers_version\": \"4.28.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 32128\n}"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:17:19.703798Z",
     "start_time": "2023-05-19T14:17:19.700196Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "output = model(\n",
    "    input_ids=encoding[\"input_ids\"],\n",
    "    attention_mask=encoding[\"attention_mask\"],\n",
    "    labels=labels\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:18:39.293770Z",
     "start_time": "2023-05-19T14:18:39.070341Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 32, 32128])"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:19:01.328796Z",
     "start_time": "2023-05-19T14:19:01.325096Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(2.2242, grad_fn=<NllLossBackward0>)"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:19:30.608242Z",
     "start_time": "2023-05-19T14:19:30.599352Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "class BioQAModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name, return_dict=True)\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        return output.loss, output.logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        loss, outputs = self(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        loss, outputs = self(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=5e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:21:26.993683Z",
     "start_time": "2023-05-19T14:21:26.990623Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/drw/venv_miniforge310/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = BioQAModel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:21:31.128428Z",
     "start_time": "2023-05-19T14:21:29.321982Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:23:54.630849Z",
     "start_time": "2023-05-19T14:23:54.626296Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=N_EPOCHS,\n",
    "    enable_progress_bar=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:25:08.217722Z",
     "start_time": "2023-05-19T14:25:08.151322Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:38:35.352404Z",
     "start_time": "2023-05-19T14:38:35.345336Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir lightning_logs/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:47:42.415040Z",
     "start_time": "2023-05-19T14:47:39.883094Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/drw/venv_miniforge310/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c6d90bec6914b3c9982c88a04eeb0d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'BioQADataset' on <module '__main__' (built-in)>\n",
      "/Users/drw/venv_miniforge310/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:45:59.555489Z",
     "start_time": "2023-05-19T14:38:53.670023Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
